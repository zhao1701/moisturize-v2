{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T06:55:33.276066Z",
     "start_time": "2019-03-31T06:55:33.127210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import git\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from pathlib import Path\n",
    "from matplotlib import rcParams\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, BatchNormalization, Conv2DTranspose\n",
    "from keras.layers import Input, Layer, Lambda, Flatten, Reshape\n",
    "from keras.layers import Multiply, Add, Input, Dense\n",
    "from keras.losses import binary_crossentropy, mse\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import Sequence\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras import backend as K\n",
    "from keras.metrics import logcosh\n",
    "\n",
    "# Find project root directory and file path constants\n",
    "repo = git.Repo('.', search_parent_directories=True)\n",
    "PROJECT_DIR = os.path.dirname(repo.git_dir)\n",
    "sys.path.append(PROJECT_DIR)\n",
    "from config import DATA_DIR, CELEB_A_DIR\n",
    "\n",
    "sns.set(context='notebook', style='whitegrid')\n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.serif'] = 'times new roman'\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T07:14:02.286295Z",
     "start_time": "2019-03-31T07:14:02.235719Z"
    }
   },
   "outputs": [],
   "source": [
    "class Variational(Layer):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, x):\n",
    "        assert(isinstance(x, list))\n",
    "        z_mu, z_log_sigma = x\n",
    "        eps = K.random_normal(K.shape(z_log_sigma))\n",
    "        z = Add()([z_mu, Multiply()([K.exp(z_log_sigma), eps])])\n",
    "        return z\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert(isinstance(input_shape, list))\n",
    "        z_mu_shape, z_log_sigma_shape = input_shape\n",
    "        assert(z_mu_shape == z_log_sigma_shape)\n",
    "        return z_mu_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T17:07:27.946092Z",
     "start_time": "2019-03-31T17:07:27.901900Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_latent_tensors(x):\n",
    "    a = Conv2D(32, 4, strides=2, padding='same', activation='relu')(x)\n",
    "    a = BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-5)(a)\n",
    "    a = Conv2D(64, 4, strides=2, padding='same', activation='relu')(a)\n",
    "    a = BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-5)(a)\n",
    "    a = Conv2D(128, 4, strides=2, padding='same', activation='relu')(a)\n",
    "    a = BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-5)(a)\n",
    "    a = Conv2D(128, 4, strides=2, padding='same', activation='relu')(a)\n",
    "    a = BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-5)(a)\n",
    "    a = Conv2D(256, 4, strides=2, padding='same', activation='relu')(a)\n",
    "    a = BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-5)(a)\n",
    "    a = Conv2D(512, 4, activation='relu')(a)\n",
    "    a = BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-5)(a)\n",
    "    \n",
    "    z_mu = Conv2D(32, 1)(a)\n",
    "    z_mu = Reshape((32,))(z_mu)\n",
    "    z_log_sigma = Conv2D(32, 1)(a)\n",
    "    z_log_sigma = Reshape((32,))(z_log_sigma)\n",
    "    z = Variational()([z_mu, z_log_sigma])\n",
    "    return z, z_mu, z_log_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T17:07:29.220923Z",
     "start_time": "2019-03-31T17:07:29.173019Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_reconstruction_tensors(z):\n",
    "    a = Reshape((1, 1, -1))(z)\n",
    "    a = Conv2DTranspose(\n",
    "            512, 1, strides=1, padding='valid', activation='relu')(a)\n",
    "    a = BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-5)(a)\n",
    "    a = Conv2DTranspose(\n",
    "            256, 4, strides=1, padding='valid', activation='relu')(a)\n",
    "    a = BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-5)(a)\n",
    "    a = Conv2DTranspose(\n",
    "            128, 4, strides=2, padding='same', activation='relu')(a)\n",
    "    a = BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-5)(a)\n",
    "    a = Conv2DTranspose(\n",
    "            128, 4, strides=2, padding='same', activation='relu')(a)\n",
    "    a = BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-5)(a)\n",
    "    a = Conv2DTranspose(\n",
    "            64, 4, strides=2, padding='same', activation='relu')(a)\n",
    "    a = BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-5)(a)\n",
    "    a = Conv2DTranspose(\n",
    "            32, 4, strides=2, padding='same', activation='relu')(a)\n",
    "    a = BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-5)(a)\n",
    "    y = Conv2DTranspose(\n",
    "            3, 4, strides=2, padding='same', activation='sigmoid')(a)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T17:07:48.100594Z",
     "start_time": "2019-03-31T17:07:48.060602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(z.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T17:59:06.703790Z",
     "start_time": "2019-03-31T17:59:06.660464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'x:0' shape=(?, 128, 128, 3) dtype=float32>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T17:58:12.105962Z",
     "start_time": "2019-03-31T17:58:12.067976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(?, 1, 1, 32) dtype=float32>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T18:11:29.508794Z",
     "start_time": "2019-03-31T18:11:29.470059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'encoder/variational_1/add_2/add:0' shape=(?, 32) dtype=float32>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T17:57:53.424099Z",
     "start_time": "2019-03-31T17:57:49.073642Z"
    }
   },
   "outputs": [],
   "source": [
    "BETA = 0.1\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "x = Input(shape=(128, 128, 3), name='x')\n",
    "z, z_mu, z_log_sigma = make_latent_tensors(x)\n",
    "encoder = Model(inputs=x, outputs=[z, z_mu, z_log_sigma], name='encoder')\n",
    "\n",
    "z_ = Input(shape=(1, 1, 32))\n",
    "y_ = make_reconstruction_tensors(z_)\n",
    "decoder = Model(inputs=z_, outputs=y_, name='decoder')\n",
    "\n",
    "y = decoder(encoder(x)[0])\n",
    "vae = Model(inputs=x, outputs=y, name='vae')\n",
    "\n",
    "reconstruction_loss = mse(x, y)\n",
    "reconstruction_loss *= 3\n",
    "reconstruction_loss = K.sum(reconstruction_loss, axis=-1)\n",
    "reconstruction_loss = K.sum(reconstruction_loss, axis=-1)\n",
    "reconstruction_loss = K.mean(reconstruction_loss)\n",
    "latent_loss = 1 + 2*z_log_sigma - K.square(z_mu) - K.exp(2*z_log_sigma)\n",
    "latent_loss = -0.5 * K.sum(latent_loss, axis=-1)\n",
    "latent_loss = K.mean(latent_loss)\n",
    "loss = reconstruction_loss + BETA * latent_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T19:13:50.797553Z",
     "start_time": "2019-03-31T19:13:50.764286Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_loss_fn(f1, f2):\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        return f1(y_true, y_pred) + f2(y_true, y_pred) \n",
    "    return loss_fn\n",
    "\n",
    "loss_fn = make_loss_fn(latent_loss, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T19:45:31.588777Z",
     "start_time": "2019-03-31T19:45:31.522125Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_latent_loss(z_mu, z_log_sigma):\n",
    "    latent_loss = 1 + 2*z_log_sigma - K.square(z_mu) - K.exp(2*z_log_sigma)\n",
    "    latent_loss = -0.5 * K.sum(latent_loss, axis=-1)\n",
    "    latent_loss = K.mean(latent_loss)\n",
    "    def latent_loss_fn(x, y):\n",
    "        return latent_loss\n",
    "    return latent_loss_fn\n",
    "\n",
    "latent_loss = make_latent_loss(z_mu, z_log_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T04:29:47.631459Z",
     "start_time": "2019-04-01T04:29:47.576498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.training.Model"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T02:48:19.088181Z",
     "start_time": "2019-04-01T02:48:19.033793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(?, 1, 1, 32) dtype=float32>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T19:45:32.668388Z",
     "start_time": "2019-03-31T19:45:32.560076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "x (InputLayer)               (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 32), (None, 32),  3087392   \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 128, 128, 3)       3070947   \n",
      "=================================================================\n",
      "Total params: 6,158,339\n",
      "Trainable params: 6,153,859\n",
      "Non-trainable params: 4,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# vae.add_loss(5e-4 * latent_loss)\n",
    "vae.compile(optimizer=Adam(lr=1e-5), metrics=[mse, latent_loss], loss=[loss_fn])\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T19:45:35.253261Z",
     "start_time": "2019-03-31T19:45:35.195185Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_img(file):\n",
    "    img = load_img(file)\n",
    "    img = img_to_array(img)\n",
    "    img /= 255.\n",
    "    return img\n",
    "\n",
    "def crop_square(img, side_length=128):\n",
    "    height, width, num_channels = img.shape\n",
    "    \n",
    "    # Crop image to square\n",
    "    extra_padding = (max(height, width) - min(height, width)) // 2\n",
    "    if height > width:\n",
    "        img = img[extra_padding:-extra_padding]\n",
    "    elif height < width:\n",
    "        img = img[:, extra_padding:-extra_padding]\n",
    "        \n",
    "    # Zoom\n",
    "    extra_padding = (min(height, width) - side_length) // 2\n",
    "    assert(extra_padding >= 0)\n",
    "    img = img[extra_padding:-extra_padding, extra_padding:-extra_padding]\n",
    "    return img\n",
    "\n",
    "class ImageDataGenerator(Sequence):\n",
    "    \n",
    "    def __init__(\n",
    "            self, data_dir, batch_size=32, shuffle=True,\n",
    "            filetype='jpg', square_crop_length=128):\n",
    "        if isinstance(data_dir, str):\n",
    "            data_dir = Path(data_dir)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.files = list(data_dir.glob('*.{}'.format(filetype)))\n",
    "        self.num_samples = len(self.files)\n",
    "        self.square_crop_length = square_crop_length\n",
    "        if self.shuffle:\n",
    "            self.files = np.random.permutation(self.files).tolist()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        idx_start = index * self.batch_size\n",
    "        idx_end = (index + 1) * self.batch_size\n",
    "        batch_files = self.files[idx_start:idx_end]\n",
    "        imgs = [read_img(file) for file in batch_files]\n",
    "        if self.square_crop_length:\n",
    "            imgs = [\n",
    "                crop_square(img, side_length=self.square_crop_length)\n",
    "                for img in imgs]\n",
    "        imgs = np.array(imgs)\n",
    "        imgs = (imgs, imgs) # Return in form (x, y)\n",
    "        return imgs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples // self.batch_size\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.files = np.random.permutation(self.files).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T19:45:47.683885Z",
     "start_time": "2019-03-31T19:45:36.016186Z"
    }
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(CELEB_A_DIR, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T19:46:05.559736Z",
     "start_time": "2019-03-31T19:45:47.737258Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2114.5375 - mean_squared_error: 0.0968 - latent_loss_fn: 2114.4417\n"
     ]
    }
   ],
   "source": [
    "history = vae.fit_generator(datagen, steps_per_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T19:50:18.080088Z",
     "start_time": "2019-03-31T19:50:18.039851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x:0'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inputs[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(25, 20, 128, 128, 3) --> (20, 128 * 5, 128 * 5, 3)\n",
    "\n",
    "# Original\n",
    "(25, 20, 128, 128, 3)\n",
    "\n",
    "# Transpose\n",
    "(20, 25, 128, 128, 3)\n",
    "\n",
    "# Reshape\n",
    "(20, 5, 5, 128, 128, 3)\n",
    "\n",
    "# Stack\n",
    "(20, 5, 5 * 128, 128, 3)\n",
    "\n",
    "# Transpose\n",
    "(20, 5 * 128, 5, 128, 3)\n",
    "\n",
    "# Stack\n",
    "(20, 5 * 128, 5 * 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T05:13:13.380337Z",
     "start_time": "2019-04-01T05:13:13.316092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 20, 5, 10)\n",
      "(20, 24, 5, 10)\n",
      "(20, 4, 6, 5, 10)\n",
      "(4, 5, 6, 10, 20)\n",
      "(20, 6, 10, 20)\n",
      "(6, 10, 20, 20)\n",
      "(60, 20, 20)\n",
      "(20, 20, 60)\n"
     ]
    }
   ],
   "source": [
    "NUM_IMAGES = 24\n",
    "NUM_TRAVERSAL_POINTS = 20\n",
    "NUM_ROWS = 4\n",
    "NUM_COLS = 6\n",
    "IMG_HEIGHT = 5\n",
    "IMG_WIDTH = 10\n",
    "\n",
    "test = np.zeros([NUM_IMAGES, NUM_TRAVERSAL_POINTS, IMG_HEIGHT, IMG_WIDTH])\n",
    "for i in range(NUM_IMAGES):\n",
    "    test[i] += i\n",
    "for i in range(NUM_TRAVERSAL_POINTS):\n",
    "    test[:, i] += 0.01 * i\n",
    "    \n",
    "print(test.shape)\n",
    "\n",
    "test = test.transpose(1, 0, 2, 3)\n",
    "print(test.shape)\n",
    "\n",
    "test = test.reshape(NUM_TRAVERSAL_POINTS, NUM_ROWS, NUM_COLS, IMG_HEIGHT, IMG_WIDTH)\n",
    "print(test.shape)\n",
    "\n",
    "test = test.transpose(1, 3, 2, 4, 0)\n",
    "print(test.shape)\n",
    "\n",
    "test = np.vstack(test)\n",
    "print(test.shape)\n",
    "\n",
    "test = test.transpose(1, 2, 0, 3)\n",
    "print(test.shape)\n",
    "\n",
    "test = np.vstack(test)\n",
    "print(test.shape)\n",
    "\n",
    "test = test.transpose(2, 1, 0)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T05:16:59.102661Z",
     "start_time": "2019-04-01T05:16:59.039187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 20, 5, 10)\n",
      "(20, 24, 5, 10)\n",
      "(20, 4, 6, 5, 10)\n",
      "(20, 4, 5, 6, 10)\n",
      "(20, 20, 60)\n"
     ]
    }
   ],
   "source": [
    "NUM_IMAGES = 24\n",
    "NUM_TRAVERSAL_POINTS = 20\n",
    "NUM_ROWS = 4\n",
    "NUM_COLS = 6\n",
    "IMG_HEIGHT = 5\n",
    "IMG_WIDTH = 10\n",
    "\n",
    "test = np.zeros([NUM_IMAGES, NUM_TRAVERSAL_POINTS, IMG_HEIGHT, IMG_WIDTH])\n",
    "for i in range(NUM_IMAGES):\n",
    "    test[i] += i\n",
    "for i in range(NUM_TRAVERSAL_POINTS):\n",
    "    test[:, i] += 0.01 * i\n",
    "print(test.shape)\n",
    "\n",
    "test = test.transpose(1, 0, 2, 3)\n",
    "print(test.shape)\n",
    "\n",
    "test = test.reshape(NUM_TRAVERSAL_POINTS, NUM_ROWS, NUM_COLS, IMG_HEIGHT, IMG_WIDTH)\n",
    "print(test.shape)\n",
    "\n",
    "test = test.transpose(0, 1, 3, 2, 4)\n",
    "print(test.shape)\n",
    "\n",
    "test = test.reshape(NUM_TRAVERSAL_POINTS, NUM_ROWS * IMG_HEIGHT, NUM_COLS * IMG_WIDTH)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T05:17:05.693452Z",
     "start_time": "2019-04-01T05:17:05.649017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  5.,  5.,  5.],\n",
       "       [ 0.,  0.,  0., ...,  5.,  5.,  5.],\n",
       "       [ 0.,  0.,  0., ...,  5.,  5.,  5.],\n",
       "       ...,\n",
       "       [18., 18., 18., ..., 23., 23., 23.],\n",
       "       [18., 18., 18., ..., 23., 23., 23.],\n",
       "       [18., 18., 18., ..., 23., 23., 23.]])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T05:32:41.052452Z",
     "start_time": "2019-04-01T05:32:41.001955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.        , -3.66666667, -3.33333333, -3.        , -2.66666667,\n",
       "       -2.33333333, -2.        , -1.66666667, -1.33333333, -1.        ,\n",
       "       -0.66666667, -0.33333333,  0.        ,  0.33333333,  0.66666667,\n",
       "        1.        ,  1.33333333,  1.66666667,  2.        ,  2.33333333,\n",
       "        2.66666667,  3.        ,  3.33333333,  3.66666667,  4.        ])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(-4, 4, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T05:45:29.640100Z",
     "start_time": "2019-04-01T05:45:29.589867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20, 60)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T05:48:13.423791Z",
     "start_time": "2019-04-01T05:48:13.373606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(z_mu.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
